{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import logging\n",
    "import pathlib\n",
    "import pyaudio\n",
    "import wave\n",
    "logger =tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img():\n",
    "    cmap = plt.get_cmap('inferno')\n",
    "    plt.figure(figsize=(8,8))\n",
    "    genres = 'plach rugan smeh '.split()\n",
    "    for g in genres:\n",
    "        pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "        for filename in os.listdir(f'C:/Users/iudicio/Desktop/White Space/{g}'):\n",
    "            songname = f'C:/Users/iudicio/Desktop/White Space/{g}/{filename}'\n",
    "            y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "            plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "            plt.axis('off');\n",
    "            plt.savefig(f'C:/Users/iudicio/Desktop/White Space/img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=os.path.join(os.path.dirname(\"C:/Users/iudicio/Desktop/White Space\"),'White Space')\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "validation_dir=os.path.join(base_dir,'validation')\n",
    "\n",
    "train_rugan_dir=os.path.join(train_dir,'rugan')\n",
    "train_plach_dir=os.path.join(train_dir,'plach')\n",
    "\n",
    "validation_rugan_dir=os.path.join(validation_dir,'rugan')\n",
    "validation_plach_dir=os.path.join(validation_dir,'plach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rugan_tr=len(os.listdir(train_rugan_dir))\n",
    "num_plach_tr=len(os.listdir(train_plach_dir))\n",
    "\n",
    "num_rugan_val=len(os.listdir(validation_rugan_dir))\n",
    "num_plach_val=len(os.listdir(validation_plach_dir))\n",
    "total_train=num_rugan_tr+num_plach_tr\n",
    "total_val=num_rugan_val+num_plach_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=5\n",
    "IMG_SHAPE=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,directory=train_dir,shuffle=True,target_size=(IMG_SHAPE,IMG_SHAPE),class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen=validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,directory=validation_dir,shuffle=True,target_size=(IMG_SHAPE,IMG_SHAPE),class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, _ =next(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(images_arr):\n",
    "    fig, axes = plt.subplots(1,5,figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img,ax in images_arr,axes:\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(3,activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 3,454,147\n",
      "Trainable params: 3,454,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 1.2832 - acc: 0.5417 - val_loss: 0.9021 - val_acc: 0.4412\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 2s 243ms/step - loss: 0.7964 - acc: 0.3958 - val_loss: 0.7227 - val_acc: 0.4412\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 0.7110 - acc: 0.4583 - val_loss: 0.7025 - val_acc: 0.4412\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.6481 - acc: 0.6042 - val_loss: 0.6277 - val_acc: 0.7059\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.5929 - acc: 0.7083 - val_loss: 1.2565 - val_acc: 0.4118\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.5658 - acc: 0.6875 - val_loss: 0.9506 - val_acc: 0.4412\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 3s 255ms/step - loss: 0.7332 - acc: 0.6042 - val_loss: 0.6679 - val_acc: 0.5588\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 3s 251ms/step - loss: 0.5969 - acc: 0.5625 - val_loss: 0.7654 - val_acc: 0.5294\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 0.4830 - acc: 0.8125 - val_loss: 0.9974 - val_acc: 0.4706\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.3821 - acc: 0.8125 - val_loss: 0.9725 - val_acc: 0.4706\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 0.4207 - acc: 0.7917 - val_loss: 0.6107 - val_acc: 0.6471\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 0.2982 - acc: 0.8333 - val_loss: 1.0584 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 0.4436 - acc: 0.8125 - val_loss: 0.9706 - val_acc: 0.5294\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.4152 - acc: 0.8125 - val_loss: 0.6584 - val_acc: 0.6176\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.3649 - acc: 0.8125 - val_loss: 0.8491 - val_acc: 0.5882\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.1411 - acc: 0.9792 - val_loss: 2.1497 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.1786 - acc: 0.9167 - val_loss: 1.6134 - val_acc: 0.5588\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.1201 - acc: 0.9792 - val_loss: 1.1725 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 2s 243ms/step - loss: 0.0900 - acc: 0.9792 - val_loss: 1.2772 - val_acc: 0.5294\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.0387 - acc: 0.9792 - val_loss: 1.1834 - val_acc: 0.5882\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img1():\n",
    "    cmap = plt.get_cmap('inferno')\n",
    "    plt.figure(figsize=(8,8))\n",
    "    genres = 'audio '.split()\n",
    "    for g in genres:\n",
    "        pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "        for filename in os.listdir(f'C:/Users/iudicio/Desktop/White Space/record/{g}'):\n",
    "            songname = f'C:/Users/iudicio/Desktop/White Space/record/{g}/{filename}'\n",
    "            y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "            plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "            plt.axis('off');\n",
    "            plt.savefig(f'C:/Users/iudicio/Desktop/White Space/test/class/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img():\n",
    "    cmap = plt.get_cmap('inferno')\n",
    "    plt.figure(figsize=(8,8))\n",
    "    genres = 'plach rugan smeh '.split()\n",
    "    for g in genres:\n",
    "        pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "        for filename in os.listdir(f'C:/Users/iudicio/Desktop/White Space/{g}'):\n",
    "            songname = f'C:/Users/iudicio/Desktop/White Space/{g}/{filename}'\n",
    "            y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "            plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "            plt.axis('off');\n",
    "            plt.savefig(f'C:/Users/iudicio/Desktop/White Space/img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = 5\n",
    "    WAVE_OUTPUT_FILENAME = \"C:/Users/iudicio/Desktop/White Space/record/audio/classoutput.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* recording\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"* done recording\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n",
      "Found 4 images belonging to 1 classes.\n",
      "[[9.9989319e-01 9.5244366e-05 1.1524113e-05]\n",
      " [1.7575532e-08 9.9998283e-01 1.7193081e-05]\n",
      " [2.6189650e-03 2.3820820e-04 9.9714285e-01]\n",
      " [3.2644644e-03 4.9273093e-04 9.9624276e-01]]\n",
      "Это плач.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "record_audio()\n",
    "make_img1()\n",
    "train_dir=\"C:/Users/iudicio/Desktop/White Space/test/\"\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,directory=train_dir,shuffle=True,target_size=(IMG_SHAPE,IMG_SHAPE),class_mode='binary')\n",
    "sample_training_images, _ =next(train_data_gen)\n",
    "a=model.predict (sample_training_images)\n",
    "#1-Плач 2-Ссоры 3-Смех\n",
    "pos = 0\n",
    "print(a)\n",
    "for i in a[0]:\n",
    "    pos+=1\n",
    "    if i==max(a[0]):\n",
    "        break\n",
    "\n",
    "if pos==1:\n",
    "    print(\"Это плач.\")\n",
    "if pos==2:\n",
    "    print(\"Это Крик.\")\n",
    "if pos==3:\n",
    "    print(\"Это смех.\")\n",
    "os.remove(\"C:/Users/iudicio/Desktop/White Space/test/class/classoutput.png\")\n",
    "os.remove(\"C:/Users/iudicio/Desktop/White Space/record/audio/classoutput.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Не удается найти указанный файл: 'C:/Users/iudicio/Desktop/White Space/test/class/classoutput.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-4fbd6cd5c0f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/iudicio/Desktop/White Space/test/class/classoutput.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/iudicio/Desktop/White Space/record/audio/classoutput.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Не удается найти указанный файл: 'C:/Users/iudicio/Desktop/White Space/test/class/classoutput.png'"
     ]
    }
   ],
   "source": [
    "os.remove(\"C:/Users/iudicio/Desktop/White Space/test/class/classoutput.png\")\n",
    "os.remove(\"C:/Users/iudicio/Desktop/White Space/record/audio/classoutput.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images belonging to 1 classes.\n",
      "[1.7575532e-08 9.9998283e-01 1.7193081e-05]\n",
      "Это Крик.\n",
      "[9.9989319e-01 9.5244366e-05 1.1524113e-05]\n",
      "Это смех.\n",
      "[3.2644644e-03 4.9273093e-04 9.9624276e-01]\n",
      "Это смех.\n",
      "[7.2322703e-09 1.4595654e-09 1.0000000e+00]\n",
      "Это смех.\n"
     ]
    }
   ],
   "source": [
    "train_dir=\"C:/Users/iudicio/Desktop/White Space/test/\"\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,directory=train_dir,shuffle=True,target_size=(IMG_SHAPE,IMG_SHAPE),class_mode='binary')\n",
    "sample_training_images, _ =next(train_data_gen)\n",
    "a=model.predict (sample_training_images)\n",
    "#1-Плач 2-Ссоры 3-Смех\n",
    "for i in a:\n",
    "    pos = 0\n",
    "    print(i)\n",
    "    for j in i:\n",
    "        pos+=1\n",
    "        if max(a[0])<0.5:\n",
    "            pos=4\n",
    "            break\n",
    "        if j==max(a[0]):\n",
    "            break\n",
    "    if pos==1:\n",
    "        print(\"Это плач.\")\n",
    "    if pos==2:\n",
    "        print(\"Это Крик.\")\n",
    "    if pos==3:\n",
    "        print(\"Это смех.\")\n",
    "    if pos==4:\n",
    "        print(\"Не распознано.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_img1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n",
      "[[0.9404691  0.00522729 0.05430365]]\n",
      "Это плач.\n"
     ]
    }
   ],
   "source": [
    "train_dir=\"C:/Users/iudicio/Desktop/White Space/test/\"\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,directory=train_dir,shuffle=True,target_size=(IMG_SHAPE,IMG_SHAPE),class_mode='binary')\n",
    "sample_training_images, _ =next(train_data_gen)\n",
    "a=model.predict (sample_training_images)\n",
    "#1-Плач 2-Ссоры 3-Смех\n",
    "pos = 0\n",
    "print(a)\n",
    "for i in a[0]:\n",
    "    pos+=1\n",
    "    if i==max(a[0]):\n",
    "        break\n",
    "\n",
    "if pos==1:\n",
    "    print(\"Это плач.\")\n",
    "if pos==2:\n",
    "    print(\"Это Крик.\")\n",
    "if pos==3:\n",
    "    print(\"Это смех.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img():\n",
    "    genres = 'plach rugan'.split()\n",
    "    for g in genres:\n",
    "        pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "        for filename in os.listdir(f'C:/Users/iudicio/Desktop/White Space/{g}'):\n",
    "            try:\n",
    "                image = cv2.imread(f'C:/Users/iudicio/Desktop/White Space/{g}/{filename}')\n",
    "                resized = cv2.resize(image,(576,576))\n",
    "                cv2.imwrite(f'C:/Users/iudicio/Desktop/White Space/img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png', resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img():\n",
    "    genres = 'plach rugan'.split()\n",
    "    for g in genres:\n",
    "        pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"img_data/{g}\")\n",
    "        for filename in os.listdir(f'C:/Users/iudicio/Desktop/White Space/{g}'):\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_data/plach\n",
      "geroi-velikoj-otechestvennoj-vojnyi_3.jpg\n",
      "igor2-07101810380938.jpg\n",
      "images (1).jfif\n",
      "images.jfif\n",
      "ljubimoj-mamochke-ot-syna-sashi.jpg\n",
      "ns32.jpg\n",
      "Petr_Ivanovich_Kirillovjpg.jpeg\n",
      "PFuqcpkPMbI.jpg\n",
      "pleshkov.jpg\n",
      "polk_4_s.jpg\n",
      "Pyotr_Nikolayevich_Krasnov.jpg\n",
      "regnum_picture_1455693975285868_normal.jpg\n",
      "s1200 (1).jfif\n",
      "s1200.jfif\n",
      "sns5355391c9e190_1024.jpg\n",
      "unnamed (1).jpg\n",
      "unnamed (2).jpg\n",
      "unnamed.jpg\n",
      "voxrovec.jpg\n",
      "Без названия.jfif\n",
      "Николай_Нестерович_Корсун.jpg\n",
      "img_data/rugan\n",
      "102.jpg\n",
      "104.jpg\n",
      "106.jpg\n",
      "108.jpg\n",
      "1509522577161967581.jpg\n",
      "1606x2393_0xd42ee437_14029626481429004904.jpeg\n",
      "19397eef788a097e474d95581aa24fa6.jpg\n",
      "2002x2759_0xd42ee437_8917296551429074371.jpeg\n",
      "250px-Зиба_Ганиева_(cropped).jpg\n",
      "450x600_0xd42ee437_1230797941429180340.gif\n",
      "846bb2ff39dce85f185b1ab3b54ee53b.jpg\n",
      "981730_600.jpg\n",
      "983573_600.jpg\n",
      "a123b0f41bffc80b81168e25bdf26ef5--soviet-union-division.jpg\n",
      "f81d39f9fb6c2ad5836e2ac87d1429c7--sniper-rifles-american-soldiers.jpg\n",
      "unnamed.jpg\n",
      "Zoya_Kosmodemyanskaya,_1941.png\n",
      "Без названия.jfif\n"
     ]
    }
   ],
   "source": [
    "make_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
